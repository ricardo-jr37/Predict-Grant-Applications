{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxW0RXrGDHth"
      },
      "source": [
        "# Importando bibliotecas necessárias.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns #visualisation\n",
        "import matplotlib.pyplot as plt #visualisation\n",
        "%matplotlib inline \n",
        "sns.set(color_codes=True)\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.io import output_notebook, push_notebook, show\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score #recall\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
        "output_notebook()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFC3Ec3PDL22",
        "outputId": "04b631d9-9519-488a-e4dd-fb4b91841de8"
      },
      "source": [
        "# Montando o drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL9pWEx7DRHE"
      },
      "source": [
        "reducedset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/hw3_ica/grantData_hw3/reducedSet.csv')\n",
        "reducedset = list(reducedset.x)\n",
        "#Dataset de treino\n",
        "treino = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/hw3_ica/grantData_hw3/training.csv')\n",
        "#Preditores/Atributos/Features\n",
        "x_train = treino[reducedset].copy()\n",
        "#Target\n",
        "y_train = treino['Class'].copy()\n",
        "y_train.loc[y_train == 'successful', ] = int(1)\n",
        "y_train.loc[y_train == 'unsuccessful', ] = int(0)\n",
        "y_train= y_train.astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie8kDpncD99p"
      },
      "source": [
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/hw3_ica/grantData_hw3/testing.csv')\n",
        "#Preditores/Atributos/Features\n",
        "x_test = df_test.drop(columns=['Class']).copy()\n",
        "#Target\n",
        "y_test = df_test['Class'].copy()\n",
        "y_test.loc[y_test == 'successful', ] = int(1)\n",
        "y_test.loc[y_test == 'unsuccessful', ] = int(0)\n",
        "y_test=y_test.astype('int') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5GPji3mYlKI"
      },
      "source": [
        "### link do dataset \n",
        "https://www.kaggle.com/c/unimelb\n",
        "\n",
        "### Partes Faltantes\n",
        "* title;\n",
        "* Abstract: Here, you introduce the main objective and overview of the work\n",
        "[Provide a short and informative view of the work, its scope and results].\n",
        "* Introduction: Here, you provide some context and background [Briefly, explore\n",
        "the literature in order to define classification and the models that can be used\n",
        "for it. Discuss some examples of application and provide the references.]\n",
        "* Methods: Here, you briefly describe your data set and the methods you use\n",
        "for classification. Provide a brief description of the methods, their pros and\n",
        "cons. [Also report and comment the main characteristics of the data. Each\n",
        "figure or table must be discussed in the text. Describe the features and the\n",
        "theoretical background of the methods you use for the classification.]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFw6hrpwH1xq"
      },
      "source": [
        "# Questão 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P16mztcGSo1h"
      },
      "source": [
        "Para auxiliar na exploração e na construção do nosso modelo, nós reduzimos a dimensão do nosso dataset. Usamos o método Embedded, é uma técnica que realiza a seleção de atributos. O processo de seleção de features é baseado em um algoritmo de machine learning, nesse caso usamos Random Forest, que realiza a seleção de variáveis durante o treinamento desse algoritmo. Esse algoritmo avalia todas as combinação possíveis de features e faz avaliação dessas combinações, como é possível ver na ilustração a seguir. Por fim, ele seleciona a melhor combinlçai de features, que fornecem os melhores os resultados. Desse modo, diminuímos 202 dimensões, o dataset original tem 252 features e novo dataset tem 50 atributos. <br><br>\n",
        "![image.png](https://www.datavedas.com/wp-content/uploads/2018/01/2.1.2.4.1.3-Embedded-Methods-1.png)\n",
        "<br><br>O algoritmo de Random Forest é nada mais do que um grupo de árvores de decisão. Destarte, cada grupo é estabelecido sobre uma extração aleatória de amostras e features do conjunto de dados, assim, uma árvore individual não é capaz de ver todas as features ou acessas todas as observações.<br><br> \n",
        "Depois de selecionar nossas features, nós vamos criar o nosso modelo de classificação. O primeiro modelos que vamos construção vamos usar o algoritmo de Regressão logísitca  **... Explicação ...** .<br><br>\n",
        "Outrossim, para validarmos os modelos criados usamos\n",
        "a técnica de cross-validation. Cross-Validation é uma técnica de validação de modelo, que serve para avaliar como os resultados da análise estatística serão generalizados para um conjunto de dados independente. É usado principalmente em configurações onde o objetivo é a classificação e se você deseja estimar a precisão da execução real do modelo de classificação. Assim, dividimos os dados de treino em 5 folds.<br><br>\n",
        "Por fim, para avaliarmos os nossos modelos adotamos algumas métricas, como: Acurácia, Recall, precisão, f1-score e a matriz de confusão.<br><br>\n",
        "Matriz de Confusão é uma forma visual simples de avaliarmos o nosso modelo. Essa matriz indica a quantidade de elementos que existem em cada grupo:  falso positivo (FP), falso negativo (FN), verdadeiro positivo (TP) e verdadeiro negativo (TN). Essa matriz possibilita visualizar quantos elementos foram classificados corretamente e erroneamente em cada classe, que auxilia a entender se o modelo está favorecendo uma classe em detrimento da outra.<br><br>\n",
        "![image.png](https://miro.medium.com/max/700/1*j0TSVygS7ZPfK-lZkojNcQ.png)\n",
        "<br><br>\n",
        "Acurácia nos informa quantos elementos, independentemente da classe, foram classificados corretamente. Essa métrica é dada pela imagem a seguir, que consiste pela soma acerta divida pelo número de elementos: <br><br>\n",
        "![image.png](https://miro.medium.com/max/700/1*FvMtz5kCu-GOI3GSgi6k4Q.png)<br><br>\n",
        "Recall, ou Revocação, essa métrica é muito comum para avaliar oum modelo de classificação. Essa métrica dá maior ênfase para os erros por elementos que foram classificados de forma negativa. O recall é dado pela razão entre a quantidade de elementos classificados como positivos e a quantidade de exemplos que são de fato positivos, conforme a fórmula abaixo: <br><br>\n",
        "![image.png](https://miro.medium.com/max/700/1*fqZ1ymVGGSA5fbqYrf1t1Q.png)<br><br>\n",
        "A Precisão é uma métrica bem comumu para avaliar modelos de classificação. Essa métrica dá um enfâse para os erros por falso positivo. A precisão é dada pela divisão entre a quantidade de elementos classificados corretamente como positivos e total de elementos classificados de forma positiva, confomra a fórmula a seguir:<br><br>\n",
        "![image.png](https://miro.medium.com/max/700/1*9yxSYzw298P_JSZuTMVEBg.png)<br><br>\n",
        "Score F1 é uma métrica que leva em consideração tanto a precisão quanto o recall. Essa métrica definida pela fórmula a seguir. Ela é uma medida diretamente proporcial à precisão e ao recall.<br><br>\n",
        "![image.png](https://miro.medium.com/max/700/1*9yxSYzw298P_JSZuTMVEBg.png)<br><br>\n",
        "\n",
        "\n",
        "** Fonte:**\n",
        "* https://medium.com/kunumi/m%C3%A9tricas-de-avalia%C3%A7%C3%A3o-em-machine-learning-classifica%C3%A7%C3%A3o-49340dcdb198\n",
        "* https://heartbeat.fritz.ai/hands-on-with-feature-selection-techniques-embedded-methods-84747e814dab\n",
        "* https://www.analyticsvidhya.com/blog/2020/10/a-comprehensive-guide-to-feature-selection-using-wrapper-methods-in-python/\n",
        "* https://towardsdatascience.com/feature-selection-using-random-forest-26d7b747597f\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LSeqiZl0S5b"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSlXGUfbDVRe",
        "outputId": "1baabed6-c6d3-4bc9-96f9-065957991a62"
      },
      "source": [
        "# Reduzir o dataset\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
        "sel.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                                 class_weight=None,\n",
              "                                                 criterion='gini',\n",
              "                                                 max_depth=None,\n",
              "                                                 max_features='auto',\n",
              "                                                 max_leaf_nodes=None,\n",
              "                                                 max_samples=None,\n",
              "                                                 min_impurity_decrease=0.0,\n",
              "                                                 min_impurity_split=None,\n",
              "                                                 min_samples_leaf=1,\n",
              "                                                 min_samples_split=2,\n",
              "                                                 min_weight_fraction_leaf=0.0,\n",
              "                                                 n_estimators=100, n_jobs=None,\n",
              "                                                 oob_score=False,\n",
              "                                                 random_state=None, verbose=0,\n",
              "                                                 warm_start=False),\n",
              "                max_features=None, norm_order=1, prefit=False, threshold=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMDTZK4sD0Q-",
        "outputId": "16709173-8db3-4b22-be94-e66054cda924"
      },
      "source": [
        "selected_feat= x_train.columns[(sel.get_support())]\n",
        "print(selected_feat)\n",
        "len(selected_feat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['NumCI', 'NumECI', 'NumSCI', 'CI.1960', 'CI.1965', 'CI.Australia',\n",
            "       'CI.PhD', 'Success.CI', 'Unsuccess.CI', 'CI.Faculty25', 'Duration0to5',\n",
            "       'Duration5to10', 'DurationGT15', 'DurationLT0', 'DurationUnk',\n",
            "       'Astar.CI', 'A.CI', 'B.CI', 'C.CI', 'AstarTotal', 'ATotal', 'BTotal',\n",
            "       'CTotal', 'Sponsor24D', 'Sponsor2B', 'Sponsor4D', 'ContractValueBandA',\n",
            "       'ContractValueBandB', 'ContractValueBandC', 'ContractValueBandD',\n",
            "       'ContractValueBandE', 'ContractValueBandF', 'ContractValueBandG',\n",
            "       'ContractValueBandUnk', 'GrantCat10A', 'GrantCat30B', 'GrantCat50A',\n",
            "       'GrantCatUnk', 'Aug', 'Jan', 'Nov', 'Oct', 'Sep', 'Fri', 'Mon', 'Sat',\n",
            "       'Thurs', 'Tues', 'Wed', 'Day'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EklI1nAD45u",
        "outputId": "740fdce9-5158-4f0c-e165-7e9aef77cf41"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(penalty='none', solver='newton-cg')\n",
        "model.fit(x_train[selected_feat], y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='none',\n",
              "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52ColHr3ErCd",
        "outputId": "1c74afaa-bace-4739-f1e5-6e81b129e3cf"
      },
      "source": [
        "# Validação Cruzada\n",
        "results = cross_validate(model, x_train[selected_feat], y_train, cv=5, return_train_score=False, scoring=['accuracy', 'precision', 'recall','f1', 'roc_auc'])\n",
        "print('Validação por cross-validation Regressão Logística:\\n\\nAcurácia média e desvio padrão: {:.3f} ({:.3f})\\n\\nRecall médio: {:.3f} ({:.3f})\\n\\nF1-SCORE médio e desvio padrão: {:.3f} ({:.3f})\\n\\nPrecisão médio e desvio padrão: {:.3f} ({:.3f})'.format(np.mean(results['test_accuracy']), np.std(results['test_accuracy']),np.mean(results['test_recall']), np.std(results['test_recall']), np.mean(results['test_f1']),np.std(results['test_f1']), np.mean(results['test_precision']),np.std(results['test_precision'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validação por cross-validation Regressão Logística:\n",
            "\n",
            "Acurácia média e desvio padrão: 0.727 (0.064)\n",
            "\n",
            "Recall médio: 0.683 (0.033)\n",
            "\n",
            "F1-SCORE médio e desvio padrão: 0.701 (0.057)\n",
            "\n",
            "Precisão médio e desvio padrão: 0.725 (0.093)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "OKjcwusNGRXh",
        "outputId": "4a068672-7070-49a9-d082-bb5c7eda421a"
      },
      "source": [
        "#Matriz de correlação - Treino\n",
        "pd.crosstab(y_train, model.predict(x_train[selected_feat]), rownames=['True'], colnames=['Predicted'], margins=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Predicted</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>All</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3579</td>\n",
              "      <td>808</td>\n",
              "      <td>4387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>737</td>\n",
              "      <td>3066</td>\n",
              "      <td>3803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All</th>\n",
              "      <td>4316</td>\n",
              "      <td>3874</td>\n",
              "      <td>8190</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Predicted     0     1   All\n",
              "True                       \n",
              "0          3579   808  4387\n",
              "1           737  3066  3803\n",
              "All        4316  3874  8190"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cxyerkKECBn",
        "outputId": "1ac05cdf-e15b-4748-9a36-372e6c67b39f"
      },
      "source": [
        "#Resultado Teste\n",
        "y_pred = model.predict(x_test[selected_feat])\n",
        "print(classification_report(y_test, y_pred))\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print('F1-SCORE: ', f1)\n",
        "acuracia = accuracy_score(y_test, y_pred)\n",
        "print('Acurácia: %f' % acuracia)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print('Precision: %f' % precision)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print('Recall: %f' % recall)\n",
        "roc = roc_auc_score(y_test, y_pred)\n",
        "print('ROC: %f' % roc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.86      0.88       329\n",
            "           1       0.77      0.83      0.80       189\n",
            "\n",
            "    accuracy                           0.85       518\n",
            "   macro avg       0.83      0.84      0.84       518\n",
            "weighted avg       0.85      0.85      0.85       518\n",
            "\n",
            "F1-SCORE:  0.7979539641943734\n",
            "Acurácia: 0.847490\n",
            "Precision: 0.772277\n",
            "Recall: 0.825397\n",
            "ROC: 0.842790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "OaIgX6lyGIla",
        "outputId": "88130e70-1f79-4c22-df94-ce0b7bbaaca6"
      },
      "source": [
        "#Matriz de correlação - Teste\n",
        "pd.crosstab(y_test, model.predict(x_test[selected_feat]), rownames=['True'], colnames=['Predicted'], margins=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Predicted</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>All</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>284</td>\n",
              "      <td>45</td>\n",
              "      <td>329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>154</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All</th>\n",
              "      <td>319</td>\n",
              "      <td>199</td>\n",
              "      <td>518</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Predicted    0    1  All\n",
              "True                    \n",
              "0          284   45  329\n",
              "1           35  154  189\n",
              "All        319  199  518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA-Zam7hH6Mj"
      },
      "source": [
        "# Questão 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-sEqHU7cZVb",
        "outputId": "0d039976-e025-4afe-9215-d8781b754f69"
      },
      "source": [
        "kernels = ['linear', 'rbf', 'poly']\n",
        "for kernel in kernels:\n",
        "  svc = SVC(kernel=kernel)\n",
        "  print(kernel)\n",
        "  svc.fit(x_train[selected_feat], y_train)\n",
        "  # Validação Cruzada\n",
        "  results = cross_validate(svc, x_train[selected_feat], y_train, cv=5, return_train_score=False, scoring=['accuracy', 'precision', 'recall', 'roc_auc'])\n",
        "  print('Validação por cross-validation Regressão Logística:\\n\\nAcurácia média e desvio padrão: {:.3f} ({:.3f})\\n\\nRecall médio: {:.3f}\\n\\nAUROC médio e desvio padrão: {:.3f} ({:.3f})\\n'.format(np.mean(results['test_accuracy']), np.std(results['test_accuracy']),np.mean(results['test_recall']), np.mean(results['test_roc_auc']),np.std(results['test_roc_auc'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear\n",
            "Validação por cross-validation Regressão Logística:\n",
            "\n",
            "Acurácia média e desvio padrão: 0.729 (0.068)\n",
            "\n",
            "Recall médio: 0.698\n",
            "\n",
            "AUROC médio e desvio padrão: 0.819 (0.055)\n",
            "\n",
            "rbf\n",
            "Validação por cross-validation Regressão Logística:\n",
            "\n",
            "Acurácia média e desvio padrão: 0.743 (0.033)\n",
            "\n",
            "Recall médio: 0.740\n",
            "\n",
            "AUROC médio e desvio padrão: 0.821 (0.031)\n",
            "\n",
            "poly\n",
            "Validação por cross-validation Regressão Logística:\n",
            "\n",
            "Acurácia média e desvio padrão: 0.603 (0.026)\n",
            "\n",
            "Recall médio: 0.239\n",
            "\n",
            "AUROC médio e desvio padrão: 0.751 (0.049)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_ye-ctmH56d",
        "outputId": "81463a58-6ed1-4d6a-9521-77a830626643"
      },
      "source": [
        "# C-Support Vector Classification\n",
        "from sklearn.svm import SVC\n",
        "svc = SVC(kernel = kernels[1])\n",
        "svc.fit(x_train[selected_feat], y_train)\n",
        "# Validação Cruzada\n",
        "results = cross_validate(svc, x_train[selected_feat], y_train, cv=5, return_train_score=False, scoring=['accuracy', 'precision', 'recall','f1', 'roc_auc'])\n",
        "print('Validação por cross-validation Regressão Logística:\\n\\nAcurácia média e desvio padrão: {:.3f} ({:.3f})\\n\\nRecall médio: {:.3f} ({:.3f})\\n\\nF1-SCORE médio e desvio padrão: {:.3f} ({:.3f})\\n\\nPrecisão médio e desvio padrão: {:.3f} ({:.3f})'.format(np.mean(results['test_accuracy']), np.std(results['test_accuracy']),np.mean(results['test_recall']), np.std(results['test_recall']), np.mean(results['test_f1']),np.std(results['test_f1']), np.mean(results['test_precision']),np.std(results['test_precision'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validação por cross-validation Regressão Logística:\n",
            "\n",
            "Acurácia média e desvio padrão: 0.743 (0.033)\n",
            "\n",
            "Recall médio: 0.740 (0.034)\n",
            "\n",
            "F1-SCORE médio e desvio padrão: 0.728 (0.029)\n",
            "\n",
            "Precisão médio e desvio padrão: 0.719 (0.050)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaQHwjbmISn4",
        "outputId": "4783024b-3e56-48e2-c2cb-c8ae426dac69"
      },
      "source": [
        "#Resultado Teste - SVM\n",
        "y_pred = svc.predict(x_test[selected_feat])\n",
        "print(classification_report(y_test, y_pred))\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print('F1-SCORE: ', f1)\n",
        "acuracia = accuracy_score(y_test, y_pred)\n",
        "print('Acurácia: %f' % acuracia)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print('Precision: %f' % precision)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print('Recall: %f' % recall)\n",
        "roc = roc_auc_score(y_test, y_pred)\n",
        "print('ROC: %f' % roc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.79      0.83       329\n",
            "           1       0.68      0.79      0.73       189\n",
            "\n",
            "    accuracy                           0.79       518\n",
            "   macro avg       0.78      0.79      0.78       518\n",
            "weighted avg       0.80      0.79      0.79       518\n",
            "\n",
            "F1-SCORE:  0.7334963325183373\n",
            "Acurácia: 0.789575\n",
            "Precision: 0.681818\n",
            "Recall: 0.793651\n",
            "ROC: 0.790442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "4wN6hkVgIkpY",
        "outputId": "490cab16-6e4c-4cb8-e5d9-5ba2261a4342"
      },
      "source": [
        "#Matriz de correlação SVM - Teste\n",
        "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Predicted</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>All</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>259</td>\n",
              "      <td>70</td>\n",
              "      <td>329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39</td>\n",
              "      <td>150</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All</th>\n",
              "      <td>298</td>\n",
              "      <td>220</td>\n",
              "      <td>518</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Predicted    0    1  All\n",
              "True                    \n",
              "0          259   70  329\n",
              "1           39  150  189\n",
              "All        298  220  518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UHddwKNKuWI",
        "outputId": "07db9566-98c6-4b49-979f-33b9e401ddfe"
      },
      "source": [
        "# KNN , K= 24\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=24)  \n",
        "knn.fit(x_train[selected_feat], y_train)\n",
        "# Validação Cruzada - KNN , K= 5 \n",
        "results = cross_validate(knn, x_train[selected_feat], y_train, cv=5, return_train_score=False, scoring=['accuracy', 'precision', 'recall','f1', 'roc_auc'])\n",
        "print('Validação por cross-validation Regressão Logística:\\n\\nAcurácia média e desvio padrão: {:.3f} ({:.3f})\\n\\nRecall médio: {:.3f} ({:.3f})\\n\\nF1-SCORE médio e desvio padrão: {:.3f} ({:.3f})\\n\\nPrecisão médio e desvio padrão: {:.3f} ({:.3f})'.format(np.mean(results['test_accuracy']), np.std(results['test_accuracy']),np.mean(results['test_recall']), np.std(results['test_recall']), np.mean(results['test_f1']),np.std(results['test_f1']), np.mean(results['test_precision']),np.std(results['test_precision'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validação por cross-validation Regressão Logística:\n",
            "\n",
            "Acurácia média e desvio padrão: 0.643 (0.028)\n",
            "\n",
            "Recall médio: 0.546 (0.061)\n",
            "\n",
            "F1-SCORE médio e desvio padrão: 0.586 (0.045)\n",
            "\n",
            "Precisão médio e desvio padrão: 0.634 (0.028)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVW0D4JSLluu",
        "outputId": "b4812ea7-a082-493b-c644-bfea77c2a654"
      },
      "source": [
        "#Resultado Teste - SVM\n",
        "y_pred = knn.predict(x_test[selected_feat])\n",
        "print(classification_report(y_test, y_pred))\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print('F1-SCORE: ', f1)\n",
        "acuracia = accuracy_score(y_test, y_pred)\n",
        "print('Acurácia: %f' % acuracia)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print('Precision: %f' % precision)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print('Recall: %f' % recall)\n",
        "roc = roc_auc_score(y_test, y_pred)\n",
        "print('ROC: %f' % roc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.82      0.78       329\n",
            "           1       0.62      0.52      0.57       189\n",
            "\n",
            "    accuracy                           0.71       518\n",
            "   macro avg       0.69      0.67      0.68       518\n",
            "weighted avg       0.70      0.71      0.70       518\n",
            "\n",
            "F1-SCORE:  0.5689655172413793\n",
            "Acurácia: 0.710425\n",
            "Precision: 0.622642\n",
            "Recall: 0.523810\n",
            "ROC: 0.670719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "vzQgFhq5LpyJ",
        "outputId": "101691b0-8e1f-4366-b5f4-46185b7c54d6"
      },
      "source": [
        "#Matriz de correlação KNN, K = 24 - Teste\n",
        "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Predicted</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>All</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>269</td>\n",
              "      <td>60</td>\n",
              "      <td>329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90</td>\n",
              "      <td>99</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All</th>\n",
              "      <td>359</td>\n",
              "      <td>159</td>\n",
              "      <td>518</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Predicted    0    1  All\n",
              "True                    \n",
              "0          269   60  329\n",
              "1           90   99  189\n",
              "All        359  159  518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap10_2SrLvbb",
        "outputId": "2b544680-73a8-45e3-b261-1da886275053"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=24)  \n",
        "knn.fit(x_train[selected_feat], y_train)\n",
        "# Validação Cruzada - KNN , K= 10 \n",
        "results = cross_validate(knn, x_train[selected_feat], y_train, cv=5, return_train_score=False, scoring=['accuracy', 'precision', 'recall', 'roc_auc'])\n",
        "print('Validação por cross-validation Regressão Logística:\\n\\nAcurácia média e desvio padrão: {:.3f} ({:.3f})\\n\\nRecall médio: {:.3f}\\n\\nAUROC médio e desvio padrão: {:.3f} ({:.3f})\\n'.format(np.mean(results['test_accuracy']), np.std(results['test_accuracy']),np.mean(results['test_recall']), np.mean(results['test_roc_auc']),np.std(results['test_roc_auc'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validação por cross-validation Regressão Logística:\n",
            "\n",
            "Acurácia média e desvio padrão: 0.643 (0.028)\n",
            "\n",
            "Recall médio: 0.546\n",
            "\n",
            "AUROC médio e desvio padrão: 0.689 (0.031)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiq0jMY1L1sb",
        "outputId": "de215a8d-cb8f-45fd-913d-b44691abb4a6"
      },
      "source": [
        "#Resultado Teste - SVM\n",
        "y_pred = knn.predict(x_test[selected_feat])\n",
        "print(classification_report(y_test, y_pred))\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print('F1-SCORE: ', f1)\n",
        "acuracia = accuracy_score(y_test, y_pred)\n",
        "print('Acurácia: %f' % acuracia)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print('Precision: %f' % precision)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print('Recall: %f' % recall)\n",
        "roc = roc_auc_score(y_test, y_pred)\n",
        "print('ROC: %f' % roc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.82      0.78       329\n",
            "           1       0.62      0.52      0.57       189\n",
            "\n",
            "    accuracy                           0.71       518\n",
            "   macro avg       0.69      0.67      0.68       518\n",
            "weighted avg       0.70      0.71      0.70       518\n",
            "\n",
            "F1-SCORE:  0.5689655172413793\n",
            "Acurácia: 0.710425\n",
            "Precision: 0.622642\n",
            "Recall: 0.523810\n",
            "ROC: 0.670719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "Cm4Rn-0bL3TK",
        "outputId": "60bd0123-757e-422a-bb04-89c02f595623"
      },
      "source": [
        "#Matriz de correlação KNN, K = 10 - Teste\n",
        "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Predicted</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>All</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>268</td>\n",
              "      <td>61</td>\n",
              "      <td>329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>105</td>\n",
              "      <td>84</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All</th>\n",
              "      <td>373</td>\n",
              "      <td>145</td>\n",
              "      <td>518</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Predicted    0    1  All\n",
              "True                    \n",
              "0          268   61  329\n",
              "1          105   84  189\n",
              "All        373  145  518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    }
  ]
}